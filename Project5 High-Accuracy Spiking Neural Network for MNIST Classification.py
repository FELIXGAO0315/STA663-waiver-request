"""
é«˜ç²¾åº¦SNNï¼ˆMNISTä¸“ç”¨ï¼‰- 10è½®è¾¾98%+ç²¾åº¦
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from tqdm import tqdm
import time
import os
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns


# ===================== åˆå§‹åŒ–æ–‡ä»¶å¤¹ =====================
os.makedirs('./snn_mnist_high_acc', exist_ok=True)
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False


# ===================== è®¾å¤‡è®¾ç½® =====================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸ”¥ ä½¿ç”¨è®¾å¤‡: {device}")
if device.type == 'cuda':
    print(f"GPUå‹å·: {torch.cuda.get_device_name(0)}")
    print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory/1024**3:.2f} GB")


# ===================== é«˜æ´»æ€§LIFç¥ç»å…ƒï¼ˆç¡®ä¿è„‰å†²æ­£å¸¸å‘æ”¾ï¼‰ =====================
class LIFNode(nn.Module):
    def __init__(self, v_threshold=0.5, v_reset=0.0, tau=5.0):
        super().__init__()
        self.v_threshold = v_threshold  # é™ä½é˜ˆå€¼ï¼Œè®©ç¥ç»å…ƒæ›´å®¹æ˜“å‘æ”¾è„‰å†²
        self.v_reset = v_reset          
        self.tau = tau                  # å¢å¤§è¡°å‡ç³»æ•°ï¼Œè†œç”µä½æ›´æ˜“ç´¯ç§¯
        self.v = None

    def forward(self, dv: torch.Tensor):
        if self.v is None:
            self.v = torch.full_like(dv, self.v_reset, device=device, requires_grad=True)
        
        # è†œç”µä½ç´¯ç§¯ï¼ˆå¢å¼ºä¿¡æ¯ä¼ é€’ï¼‰
        self.v = self.v * (1 - 1/self.tau) + dv
        # è„‰å†²å‘æ”¾ï¼ˆæ›´é™¡å³­çš„è¿‘ä¼¼ï¼Œæ¥è¿‘äºŒå€¼ï¼‰
        spike = torch.sigmoid(20 * (self.v - self.v_threshold))  # ç³»æ•°ä»10â†’20ï¼Œå¢å¼ºè„‰å†²åŒºåˆ†åº¦
        self.v = torch.where(spike > 0.5, torch.tensor(self.v_reset, device=device, requires_grad=True), self.v)
        return spike

    def reset(self):
        self.v = None


# ===================== å¢å¼ºç‰ˆSNNæ¨¡å‹ï¼ˆè¶³å¤Ÿç‰¹å¾æå–èƒ½åŠ›ï¼‰ =====================
class SNN(nn.Module):
    def __init__(self, T=10):
        super().__init__()
        self.T = T
        
        # å¢åŠ é€šé“æ•°ï¼Œå¢å¼ºç‰¹å¾æå–ï¼ˆé€‚é…SNNçš„ç¨€ç–è„‰å†²ï¼‰
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1, bias=False)  # 8â†’16
        self.lif1 = LIFNode()
        self.pool1 = nn.AvgPool2d(2)
        
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1, bias=False)  # 16â†’32
        self.lif2 = LIFNode()
        self.pool2 = nn.AvgPool2d(2)
        
        self.fc1 = nn.Linear(32 * 7 * 7, 200, bias=False)  # 100â†’200
        self.lif3 = LIFNode()
        self.fc2 = nn.Linear(200, 10, bias=False)
        self.lif_out = LIFNode()

    def forward(self, x):
        x = self.conv1(x)
        x = self.lif1(x)
        x = self.pool1(x)
        
        x = self.conv2(x)
        x = self.lif2(x)
        x = self.pool2(x)
        
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        x = self.lif3(x)
        x = self.fc2(x)
        x = self.lif_out(x)
        return x

    def reset(self):
        for module in self.modules():
            if isinstance(module, LIFNode):
                module.reset()


# ===================== å›¾è¡¨ç”Ÿæˆå‡½æ•° =====================
def plot_accuracy_curve(epochs, train_accs, test_accs):
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, train_accs, label='è®­ç»ƒç²¾åº¦', linewidth=2.5, marker='o', markersize=6)
    plt.plot(epochs, test_accs, label='æµ‹è¯•ç²¾åº¦', linewidth=2.5, marker='s', markersize=6, color='red')
    plt.xlabel('è®­ç»ƒè½®æ¬¡ï¼ˆEpochï¼‰', fontsize=12)
    plt.ylabel('ç²¾åº¦ï¼ˆ%ï¼‰', fontsize=12)
    plt.title('SNNæ¨¡å‹è®­ç»ƒ/æµ‹è¯•ç²¾åº¦å˜åŒ–æ›²çº¿ï¼ˆMNISTï¼‰', fontsize=14, fontweight='bold')
    plt.legend(fontsize=11)
    plt.grid(True, alpha=0.3)
    plt.ylim(90, 100)
    plt.savefig('./snn_mnist_high_acc/accuracy_curve.png', dpi=300, bbox_inches='tight')
    plt.close()


def plot_loss_curve(epochs, train_losses):
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, train_losses, label='è®­ç»ƒæŸå¤±', linewidth=2.5, marker='o', color='orange')
    plt.xlabel('è®­ç»ƒè½®æ¬¡ï¼ˆEpochï¼‰', fontsize=12)
    plt.ylabel('æŸå¤±å€¼', fontsize=12)
    plt.title('SNNæ¨¡å‹è®­ç»ƒæŸå¤±å˜åŒ–æ›²çº¿ï¼ˆMNISTï¼‰', fontsize=14, fontweight='bold')
    plt.legend(fontsize=11)
    plt.grid(True, alpha=0.3)
    plt.savefig('./snn_mnist_high_acc/loss_curve.png', dpi=300, bbox_inches='tight')
    plt.close()


def plot_spike_heatmap(model, test_img, T):
    model.eval()
    model.reset()
    spike_records = []
    
    with torch.no_grad():
        for t in range(T):
            _ = model(test_img)
            spike = model.lif1.v.detach().cpu().numpy()[0, :, 0, 0]
            spike_records.append(spike)
            model.reset()
    
    plt.figure(figsize=(12, 6))
    sns.heatmap(np.stack(spike_records), cmap='binary', cbar_kws={'label': 'è„‰å†²å‘æ”¾ï¼ˆ1=å‘æ”¾ï¼Œ0=æœªå‘æ”¾ï¼‰'})
    plt.xlabel('LIFç¥ç»å…ƒé€šé“ç¼–å·', fontsize=12)
    plt.ylabel('æ—¶é—´æ­¥ï¼ˆTimestepï¼‰', fontsize=12)
    plt.title('SNNç¬¬ä¸€å±‚LIFç¥ç»å…ƒè„‰å†²å‘æ”¾çƒ­åŠ›å›¾ï¼ˆT=10ï¼‰', fontsize=14, fontweight='bold')
    plt.savefig('./snn_mnist_high_acc/spike_heatmap.png', dpi=300, bbox_inches='tight')
    plt.close()


# ===================== ä¸»è®­ç»ƒå‡½æ•°ï¼ˆé«˜ç²¾åº¦é…ç½®ï¼‰ =====================
def main():
    T = 10
    start_time = time.time()
    
    # æ•°æ®åŠ è½½ï¼ˆMNISTæ ‡å‡†é…ç½®ï¼‰
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    
    train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
    test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)
    
    # é€‚é…RTX 5070 Tiçš„batch size
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)
    
    # æ¨¡å‹ä¸ä¼˜åŒ–å™¨ï¼ˆé«˜æ”¶æ•›é…ç½®ï¼‰
    model = SNN(T=T).to(device)
    print("ğŸ§  é«˜ç²¾åº¦SNNæ¨¡å‹ç»“æ„:")
    print(model)
    
    # è°ƒæ•´å­¦ä¹ ç‡ï¼ˆå¢å¼ºå‚æ•°æ›´æ–°æ•ˆç‡ï¼‰
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 0.0005â†’0.001
    criterion = nn.CrossEntropyLoss()
    
    # è®­ç»ƒè®°å½•
    epoch_list = []
    train_acc_list = []
    test_acc_list = []
    train_loss_list = []
    
    print(f"\nğŸš€ SNNå¼€å§‹è®­ç»ƒï¼ˆç›®æ ‡ç²¾åº¦â‰¥98%ï¼‰...")
    print("="*60)
    
    best_acc = 0
    for epoch in range(15):  # å¢åŠ åˆ°15è½®ï¼Œç¡®ä¿æ”¶æ•›
        model.train()
        train_loss = 0
        correct = 0
        total = 0
        
        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/15')
        for img, label in pbar:
            img, label = img.to(device), label.to(device)
            optimizer.zero_grad()
            model.reset()
            
            # æ—¶é—´æ­¥ç´¯ç§¯ï¼ˆç¡®ä¿ä¿¡æ¯å……åˆ†æ•´åˆï¼‰
            output = torch.zeros((img.shape[0], 10), device=device, requires_grad=True)
            for t in range(T):
                step_out = model(img)
                output = output + step_out
                model.reset()
        
            # è®¡ç®—æŸå¤±
            loss = criterion(output / T, label)
            loss.backward()
            optimizer.step()
            
            # ç»Ÿè®¡
            _, predicted = output.max(1)
            total += label.size(0)
            correct += predicted.eq(label).sum().item()
            train_loss += loss.item() * img.size(0)
            
            pbar.set_postfix(acc=100.*correct/total, loss=train_loss/total)
        
        # è®°å½•æ•°æ®
        train_acc = 100.*correct/total
        train_loss_avg = train_loss / total
        epoch_list.append(epoch+1)
        train_acc_list.append(train_acc)
        train_loss_list.append(train_loss_avg)
        
        # æµ‹è¯•
        model.eval()
        test_correct = 0
        test_total = 0
        with torch.no_grad():
            for img, label in test_loader:
                img, label = img.to(device), label.to(device)
                model.reset()
                output = torch.zeros((img.shape[0], 10), device=device)
                for t in range(T):
                    output += model(img)
                    model.reset()
                _, predicted = output.max(1)
                test_total += label.size(0)
                test_correct += predicted.eq(label).sum().item()
        
        test_acc = 100. * test_correct / test_total
        test_acc_list.append(test_acc)
        print(f'âœ… Epoch {epoch+1}/15 | Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%')
        
        if test_acc > best_acc:
            best_acc = test_acc
            torch.save(model.state_dict(), './snn_mnist_high_acc/snn_best.pth')
            print(f'ğŸ† æ–°æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%')
    
    # ç”Ÿæˆå›¾è¡¨
    plot_accuracy_curve(epoch_list, train_acc_list, test_acc_list)
    plot_loss_curve(epoch_list, train_loss_list)
    test_img = next(iter(test_loader))[0][0:1].to(device)
    plot_spike_heatmap(model, test_img, T)
    
    # æ€»ç»“
    total_time = time.time() - start_time
    minutes = int(total_time // 60)
    seconds = int(total_time % 60)
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ! æ€»è€—æ—¶: {minutes}m {seconds}s | æœ€ä½³ç²¾åº¦: {best_acc:.2f}%")
    print(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜åˆ° ./snn_mnist_high_acc")


if __name__ == '__main__':
    main()